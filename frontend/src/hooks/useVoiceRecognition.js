/**
 * useVoiceRecognition.js
 * 
 * Web Speech APIë¥¼ ë˜í•‘í•˜ëŠ” ì»¤ìŠ¤í…€ í›…
 * ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³  ìƒíƒœë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
 * 
 * @created 2026-02-02
 */

import { useState, useEffect, useCallback, useRef } from 'react';

// Web Speech API ì§€ì› í™•ì¸
const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

/**
 * ìŒì„± ì¸ì‹ ì»¤ìŠ¤í…€ í›…
 * 
 * @param {Object} options - ì˜µì…˜
 * @param {string} options.lang - ì–¸ì–´ ì„¤ì • (ê¸°ë³¸: 'ko-KR')
 * @param {boolean} options.continuous - ì—°ì† ì¸ì‹ ì—¬ë¶€ (ê¸°ë³¸: false)
 * @param {boolean} options.interimResults - ì¤‘ê°„ ê²°ê³¼ í‘œì‹œ ì—¬ë¶€ (ê¸°ë³¸: true)
 * @param {Function} options.onResult - ìµœì¢… ê²°ê³¼ ì½œë°±
 * @param {Function} options.onInterimResult - ì¤‘ê°„ ê²°ê³¼ ì½œë°±
 * @returns {Object} ìŒì„± ì¸ì‹ ìƒíƒœ ë° ë©”ì„œë“œ
 */
export function useVoiceRecognition({
    lang = 'ko-KR',
    continuous = false,
    interimResults = true,
    onResult,
    onInterimResult
} = {}) {
    const [isListening, setIsListening] = useState(false);
    const [transcript, setTranscript] = useState('');
    const [interimTranscript, setInterimTranscript] = useState('');
    const [error, setError] = useState(null);
    const [isSupported, setIsSupported] = useState(true);

    const recognitionRef = useRef(null);
    const onResultRef = useRef(onResult);
    const onInterimResultRef = useRef(onInterimResult);

    // ì½œë°± ref ì—…ë°ì´íŠ¸
    useEffect(() => {
        onResultRef.current = onResult;
        onInterimResultRef.current = onInterimResult;
    }, [onResult, onInterimResult]);

    // ì´ˆê¸°í™”
    useEffect(() => {
        if (!SpeechRecognition) {
            setIsSupported(false);
            setError('ìŒì„± ì¸ì‹ì´ ì§€ì›ë˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤. Chrome ë˜ëŠ” Edgeë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.');
            return;
        }

        const recognition = new SpeechRecognition();
        recognition.lang = lang;
        recognition.continuous = continuous;
        recognition.interimResults = interimResults;

        recognition.onstart = () => {
            console.log('[Voice] ğŸ¤ ìŒì„± ì¸ì‹ ì‹œì‘');
            setIsListening(true);
            setError(null);
        };

        recognition.onend = () => {
            console.log('[Voice] ğŸ”‡ ìŒì„± ì¸ì‹ ì¢…ë£Œ');
            setIsListening(false);
        };

        recognition.onerror = (event) => {
            console.log('[Voice] âŒ ì˜¤ë¥˜ ë°œìƒ:', event.error);
            setIsListening(false);
            switch (event.error) {
                case 'not-allowed':
                    setError('ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
                    break;
                case 'no-speech':
                    setError('ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
                    break;
                case 'audio-capture':
                    setError('ë§ˆì´í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì´í¬ê°€ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.');
                    break;
                case 'network':
                    setError('ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
                    break;
                case 'aborted':
                    // ì‚¬ìš©ìê°€ ì¤‘ë‹¨í•œ ê²½ìš° ì—ëŸ¬ë¡œ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
                    break;
                default:
                    setError(`ìŒì„± ì¸ì‹ ì˜¤ë¥˜: ${event.error}`);
            }
        };

        recognition.onresult = (event) => {
            console.log('[Voice] ğŸ“ ê²°ê³¼ ìˆ˜ì‹ :', event.results);
            let finalTranscript = '';
            let interim = '';

            for (let i = event.resultIndex; i < event.results.length; i++) {
                const result = event.results[i];
                if (result.isFinal) {
                    finalTranscript += result[0].transcript;
                } else {
                    interim += result[0].transcript;
                }
            }

            console.log('[Voice] ìµœì¢…:', finalTranscript, 'ì¤‘ê°„:', interim);

            if (finalTranscript) {
                setTranscript(prev => prev + finalTranscript);
                onResultRef.current?.(finalTranscript);
            }

            if (interim) {
                setInterimTranscript(interim);
                onInterimResultRef.current?.(interim);
            } else {
                setInterimTranscript('');
            }
        };

        recognitionRef.current = recognition;

        return () => {
            recognition.abort();
        };
    }, [lang, continuous, interimResults]);

    // ìŒì„± ì¸ì‹ ì‹œì‘
    const startListening = useCallback(() => {
        if (!recognitionRef.current) return;

        setTranscript('');
        setInterimTranscript('');
        setError(null);

        try {
            recognitionRef.current.start();
        } catch (err) {
            // ì´ë¯¸ ì‹œì‘ëœ ê²½ìš° ì—ëŸ¬ ë¬´ì‹œ
            if (err.name !== 'InvalidStateError') {
                setError('ìŒì„± ì¸ì‹ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
            }
        }
    }, []);

    // ìŒì„± ì¸ì‹ ì¤‘ì§€
    const stopListening = useCallback(() => {
        if (!recognitionRef.current) return;
        recognitionRef.current.stop();
    }, []);

    // ìŒì„± ì¸ì‹ ì·¨ì†Œ (ê²°ê³¼ íê¸°)
    const abortListening = useCallback(() => {
        if (!recognitionRef.current) return;
        recognitionRef.current.abort();
        setTranscript('');
        setInterimTranscript('');
    }, []);

    // í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
    const resetTranscript = useCallback(() => {
        setTranscript('');
        setInterimTranscript('');
    }, []);

    return {
        // ìƒíƒœ
        isListening,
        transcript,
        interimTranscript,
        error,
        isSupported,
        // ë©”ì„œë“œ
        startListening,
        stopListening,
        abortListening,
        resetTranscript
    };
}

export default useVoiceRecognition;
